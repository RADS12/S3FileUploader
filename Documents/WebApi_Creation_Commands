# -------------------------------------
# Create a folder for your solution
# -------------------------------------
mkdir WebApiDemo
cd WebApiDemo

# Create solution
dotnet new sln -n WebApiDemo

# Create Web API project
dotnet new webapi -n MyWebApi

# Add Web API project to solution
dotnet sln add MyWebApi/MyWebApi.csproj

# (Optional) Create unit test project
dotnet new xunit -n MyWebApi.Tests
dotnet sln add MyWebApi.Tests/MyWebApi.Tests.csproj
dotnet add MyWebApi.Tests/MyWebApi.Tests.csproj reference MyWebApi/MyWebApi.csproj

# Build solution
dotnet build

# Run Web API (local dev)
cd MyWebApi
dotnet run

# Run tests (if added)
cd ../MyWebApi.Tests
dotnet test

# -------------------------------------
# PUBLISHING COMMANDS
# -------------------------------------

# Go back to WebApi project folder
cd ../MyWebApi

# Publish for local folder output
dotnet publish -c Release -o ./publish

# Publish self-contained (include runtime, replace win-x64 with linux-x64 if needed)
dotnet publish -c Release -r win-x64 --self-contained true -o ./publish


# -------------------------------------
# Api code:
# -------------------------------------

dotnet add package AWSSDK.S3
dotnet add FileUploaderApi package Swashbuckle.AspNetCore

# Add controller, Docker file etc.

# -------------------------------------
# Run locally:
# -------------------------------------
# In project folder:
dotnet clean
dotnet build
dotnet run

# OR Using Docker:
docker build -t fileuploaderapi .
docker run -p 8080:8080 -e ASPNETCORE_ENVIRONMENT=Development fileuploaderapi

# OR from the solution root (where Dockerfile is)
docker build -t fileuploaderapi:latest .
docker run -p 8080:8080 fileuploaderapi:latest

# -------------------------------------
# Website:
# -------------------------------------

http://localhost:8080/swagger

# -------------------------------------
# Manually run API endpoints:
# -------------------------------------
# Quick cURL tests
Upload (multipart to API):
curl -F "file=@./somefile.pdf" http://localhost:8080/api/fileupload/upload
→ {"key":"<generated-key>"}

# Get presigned download URL:
curl "http://localhost:8080/api/fileupload/download-url/<key>"

# Get presigned upload URL (client PUT directly to S3):
curl -X POST http://localhost:8080/api/fileupload/upload-url \
  -H "Content-Type: application/json" \
  -d '{"desiredKey":"myfolder/test.bin","minutes":15}'

# Then PUT the file directly:
curl -X PUT "<returned url>" --data-binary @./test.bin -H "Content-Type: application/octet-stream"

# -------------------------------------
# Git commands:
# -------------------------------------
# 1. Go to your solution root folder (where .sln is)
cd "C:\Path\To\S3FileUploader"

# 2. Initialize a new git repo (only once)
git init

# 3. Add all files for commit
git add .

# 4. Commit the files
git commit -m "Initial commit for S3FileUploader"

# 5. Rename current branch to main (GitHub default)
git branch -M main

# 6. Add remote (link local repo to GitHub repo)
git remote add origin https://github.com/Rads12/S3FileUploader.git

# 7. If remote was already set and wrong, update instead:
# git remote set-url origin https://github.com/Rads12/S3FileUploader.git

# 8. Verify the remote is correct
git remote -v

# 9. Push local main branch to remote (first time uses -u)
git push -u origin main

# 10. If remote already had commits (like README), sync before pushing
# (pull with rebase to avoid merge commits)
git pull --rebase origin main
git push -u origin main

# 11. Check which branches are tracking which remotes
git branch -vv

# 12. Set local main to track remote main explicitly
git branch -u origin/main

# 13. If you ever need to force overwrite remote with your local
# (use with caution!)
# git push --force-with-lease origin main

# -------------------------------------
# Create ECR repo and then push Docker Image:
# -------------------------------------
# Set region
AWS_REGION=us-east-2

# Get account ID
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

# Create ECR repo (safe to re-run; it errors if exists)
aws ecr create-repository --repository-name fileuploaderapi --region $AWS_REGION || true

# Login Docker to ECR
aws ecr get-login-password --region $AWS_REGION | \
  docker login --username AWS --password-stdin ${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com

# Tag & push
docker tag fileuploaderapi:latest ${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/fileuploaderapi:latest
docker push ${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/fileuploaderapi:latest

# -------------------------------------
# Pushing the code to AWS with Terraform:
# -------------------------------------

terraform fmt      # optional: auto-format
terraform validate 

terraform init
terraform show (OPtional)
# use timestamp
$tag = (Get-Date -Format "yyyyMMdd-HHmmss")

# or: git short SHA
$tag = (git rev-parse --short HEAD)

# or: both (recommended)
$tag = "$(git rev-parse --short HEAD)-$(Get-Date -Format 'yyyyMMdd-HHmmss')"

terraform apply -auto-approve -var="bucket_name=rad-s3-demo-first-1" -var="image_tag=$tag" -var="docker_context=../s3fileuploader" -var="dockerfile=Dockerfile"

#Quick fix (Windows)

# Start Docker Desktop (and switch to Linux containers):
# Launch Docker Desktop from Start menu.
# If it says “Switch to Linux containers…”, click it (you want Linux).
# Wait until the whale icon says “Docker is running”.

# Verify Docker works:
docker version
docker info
docker run --rm hello-world
# All three should succeed.

# Verify AWS CLI + account/region:
aws sts get-caller-identity
aws ecr describe-repositories --region us-east-2

# Manually test ECR login (same registry Terraform uses):
aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 675016865089.dkr.ecr.us-east-2.amazonaws.com
  
aws sts get-caller-identity --query Account --output text
aws ecr describe-repositories --repository-names file-uploader-api --region us-east-2

-----------------

#Copilot fix
"C:\Users\radkr\OneDrive\Documents\Projects\S3FileUploader"; docker build -t file-uploader-api:dev .

docker system prune -f

"C:\Users\radkr\OneDrive\Documents\Projects\S3FileUploader\Infrastructure"; terraform apply -auto-approve


-----------------
#The above didn't work so trying this
"C:\Users\radkr\OneDrive\Documents\Projects\S3FileUploader"

docker build -t file-uploader-api:dev .
#Much faster with prune and .dockerignore fix

docker tag file-uploader-api:dev 675016865089.dkr.ecr.us-east-2.amazonaws.com/file-uploader-api:dev

aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 675016865089.dkr.ecr.us-east-2.amazonaws.com

docker push 675016865089.dkr.ecr.us-east-2.amazonaws.com/file-uploader-api:dev

#Again do the App Runner step
cd "C:\Users\radkr\OneDrive\Documents\Projects\S3FileUploader\Infrastructure"; terraform plan

"C:\Users\radkr\OneDrive\Documents\Projects\S3FileUploader\Infrastructure"; terraform apply -auto-approve

#  Error: creating App Runner Service (file-uploader-api): 
#  operation error AppRunner: CreateService, https response error StatusCode: 400, 
#  RequestID: 9cd913b7-3cba-40cc-afca-d66976934f35, api error SubscriptionRequiredException: 
#  The AWS Access Key Id needs a subscription for the service
aws apprunner list-services --region us-east-2

#Didn't work, so changed to Fargate which doesn't need App Runner subscription
# What Will Be Created (10 resources):
# ECS Cluster - Container orchestration platform
# ECS Task Definition - Container specification
# ECS Service - Runs and maintains desired container count
# Application Load Balancer - Public endpoint for your API
# ALB Target Group - Routes traffic to containers
# ALB Listener - Listens on port 80
# Security Group - Network access rules
# CloudWatch Log Group - Container logs
# ECS Execution Role - Permissions for ECS tasks
# IAM Policy Attachment - Links permissions

terraform apply -auto-approve

# Outputs:

# bucket_in_use = "rad-s3-demo-first-1"
# ecr_repository = "675016865089.dkr.ecr.us-east-2.amazonaws.com/file-uploader-api"
# ecs_cluster = "file-uploader-api"
# image_tag_used = "dev"
# load_balancer_dns = "file-uploader-api-1896670076.us-east-2.elb.amazonaws.com"
# service_url = "http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com"

# App URL:
http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com/swagger

# Test upload (replace with actual file path):
curl -F "file=@C:\Path\To\Your\File.pdf" http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com/api/fileupload/upload

# Test download URL generation (replace with actual key from upload response):
curl "http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com/api/fileupload/download-url/<key>"
# Should return a presigned S3 URL for downloading the file directly. 
# You can open that URL in a browser or use curl to download the file.  
# Example:
# curl "<presigned-url>" -o downloadedfile.pdf  
# -------------------------------------
# Terraform variable overrides:
# ------------------------------------- 
# You can set variables via CLI -var, environment TF_VAR_*, or terraform.tfvars file.
# Examples:
# CLI:
terraform apply -var="bucket_name=your-bucket-name" -var="image_tag=your-image-tag"
# Env (PowerShell):
$env:TF_VAR_bucket_name = "your-bucket-name"
$env:TF_VAR_image_tag = "your-image-tag"
terraform apply
# terraform.tfvars (create this file):
bucket_name = "your-bucket-name"
image_tag   = "your-image-tag"
# Then just run:
terraform apply
# -------------------------------------
# Notes:
# -------------------------------------
# - Ensure AWS credentials have necessary permissions for ECR, ECS, S3, IAM, VPC, etc.
# - Clean up resources with `terraform destroy` when done to avoid charges.
# - Adjust region, instance sizes, and scaling as needed for your use case.
# - Monitor logs via CloudWatch for troubleshooting.
# - For production, consider using HTTPS with a proper domain and certificate.
# - This setup is basic and can be enhanced with CI/CD, autoscaling, backups, etc.
# - Always follow best practices for security, cost management, and scalability.
# - Refer to AWS and Terraform documentation for advanced configurations.
# -------------------------------------
# Example terraform.tfvars file:
# bucket_name = "your-bucket-name"
# image_tag   = "your-image-tag"  
# docker_context = "../s3fileuploader" # path to folder containing Dockerfile (project root)
# dockerfile = "Dockerfile"           # Dockerfile name (if not standard)
# region = "us-east-2"                # AWS region
# repo_name = "file-uploader-api"     # ECR repository name
# -------------------------------------
# Example commands to set variables and run terraform:
# Set variables via environment (PowerShell):
$env:TF_VAR_bucket_name = "rad-s3-demo-first-1"
$env:TF_VAR_image_tag = "dev"
terraform apply
# Or via CLI: 
terraform apply -var="bucket_name=rad-s3-demo-first-1" -var="image_tag=dev"
# Or via terraform.tfvars file:
# Create terraform.tfvars with: 
bucket_name = "rad-s3-demo-first-1"
image_tag   = "dev"
docker_context = "../s3fileuploader" # path to folder containing Dockerfile (project root)
dockerfile = "Dockerfile"           # Dockerfile name (if not standard)
region = "us-east-2"                # AWS region
repo_name = "file-uploader-api"     # ECR repository name
# Then just run:
terraform apply
# -------------------------------------

curl -I http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com (This needed URL)
# So used
Invoke-WebRequest -Uri "http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com" -Method Head
#Still didn't work The 503 error means the Load Balancer can't reach your ECS service. 
# This is common when ECS is still starting up. Let me check the ECS service status:
aws ecs describe-services --cluster file-uploader-api --services file-uploader-api --region us-east-2
# I found the issue! The ECS task is failing because it's trying to use the App Runner instance role 
# instead of the ECS execution role. Look at this error:
terraform apply -auto-approve
# Outputs:

# bucket_in_use = "rad-s3-demo-first-1"
# ecr_repository = "675016865089.dkr.ecr.us-east-2.amazonaws.com/file-uploader-api"
# ecs_cluster = "file-uploader-api"
# image_tag_used = "dev"
# load_balancer_dns = "file-uploader-api-1896670076.us-east-2.elb.amazonaws.com"
# service_url = "http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com"

aws ecs update-service --cluster file-uploader-api --service file-uploader-api --force-new-deployment --region us-east-2
#I found the issue! The apprunner_instance_role has a trust policy for tasks.apprunner.amazonaws.com, 
# but we're using it as an ECS task role, which needs to trust ecs-tasks.amazonaws.com. Let me fix this:
# Fixed iam.tf
terraform apply -auto-approve
# Outputs:

# bucket_in_use = "rad-s3-demo-first-1"
# ecr_repository = "675016865089.dkr.ecr.us-east-2.amazonaws.com/file-uploader-api"
# ecs_cluster = "file-uploader-api"
# image_tag_used = "dev"
# load_balancer_dns = "file-uploader-api-1896670076.us-east-2.elb.amazonaws.com"
# service_url = "http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com"

aws ecs update-service --cluster file-uploader-api --service file-uploader-api --force-new-deployment --region us-east-2

#Describe the service to check task status:
aws ecs describe-services --cluster file-uploader-api --services file-uploader-api --region us-east-2 
--query 'services[0].{runningCount:runningCount,desiredCount:desiredCount,deployments:deployments[0].rolloutState}'
#Still creating so checking latest events:
aws ecs describe-services --cluster file-uploader-api --services file-uploader-api --region us-east-2 --query 'services[0].events[0:3]'
#This was good

#Chcek the health
Start-Sleep 60; (Optional)
Invoke-WebRequest -Uri "http://file-uploader-api-1896670076.us-east-2.elb.amazonaws.com" -Method Head -TimeoutSec 10

#check the ECS service logs to see what's happening with the container:
aws logs tail /ecs/file-uploader-api --region us-east-2 --since 10m

# The container is failing because of "Permission denied" when trying to bind to port 80. This is because:

# Non-root user: The Dockerfile creates a non-root user appuser
# Port 80 is privileged: Only root can bind to ports below 1024
# Container runs as appuser: So it can't bind to port 80
# Solution: Change Container Port to 8080
# Let me fix this by updating the ECS task definition to use port 8080 instead of port 80:

# Let me read the ECS task definition to see the exact format:
terraform apply -auto-approve

# The terraform apply failed because there's a dependency issue with the target group. Let me fix this by first stopping the ECS service, then applying the changes:
aws ecs update-service --cluster file-uploader-api --service file-uploader-api --desired-count 0 --region us-east-2

# Now let me wait a moment for the service to fully drain its connections and then apply the Terraform changes:
terraform apply -auto-approve
# Error: deleting ELBv2 Target Group (arn:aws:elasticloadbalancing:us-east-2:675016865089:targetgroup/file-uploader-api/fa4fe8598130f6ec): 
# operation error Elastic Load Balancing v2: DeleteTargetGroup, https response error StatusCode: 400, 
# RequestID: 34722147-3a8a-4665-a59e-5faeedbf6e4f, ResourceInUse: 
# Target group 'arn:aws:elasticloadbalancing:us-east-2:675016865089:targetgroup/file-uploader-api/fa4fe8598130f6ec' 
# is currently in use by a listener or a rule

terraform apply -auto-approve

aws elbv2 describe-listeners --load-balancer-arn arn:aws:elasticloadbalancing:us-east-2:675016865089:loadbalancer/app/file-uploader-api/61c84264c2341ad1 --region us-east-2

ws elbv2 create-target-group --name file-uploader-api-port8080 --protocol HTTP --port 8080 --vpc-id vpc-04e1ba06138b7ffe7 --target-type ip --health-check-path /health --region us-east-2

aws elbv2 modify-listener --listener-arn arn:aws:elasticloadbalancing:us-east-2:675016865089:listener/app/file-uploader-api/61c84264c2341ad1/778793ec3088e219 --default-actions Type=forward,TargetGroupArn=arn:aws:elasticloadbalancing:us-east-2:675016865089:targetgroup/file-uploader-api-port8080/6e2469af469036aa --region us-east-2

aws elbv2 delete-target-group --target-group-arn arn:aws:elasticloadbalancing:us-east-2:675016865089:targetgroup/file-uploader-api/fa4fe8598130f6ec --region us-east-2

terraform import aws_lb_target_group.api arn:aws:elasticloadbalancing:us-east-2:675016865089:targetgroup/file-uploader-api-port8080/6e2469af469036aa



